---
title: 移动端直播应用的开发流程
date: 2016-05-09 10:14:54
tags:
- 音视频处理
---

## Part 1. 推流端

推流，就是将采集到的音频，视频数据通过流媒体协议发送到流媒体服务器。

### 一、选择流媒体协议

现在直播应用，采用 RTMP 协议居多，也有部分使用 HLS 协议。

采用RTMP协议，就要看下它与流媒体服务器交互的过程，RTMP协议的默认端口是1935，采用 TCP 协议。并且需要了解 FLV 的封装格式。

采用 HLS 协议，因为涉及到切片，延时会比较大，需要了解 TS 流。

<!-- more -->

### 二、采集音视频数据

做直播，数据的来源不可缺少，就是采集摄像头，麦克风的数据。

iOS 平台上采集音视频数据，需要使用 AVFoundation.Framework 框架，从 captureSession 会话的回调中获取音频，视频数据。

### 三、硬编码，软编码音视频数据

软编码就是利用 CPU 资源来压缩音视频数据，硬编码与之相反。

软编码的话，现在广泛采用 FFmpeg 库结合编码库来实现，FFmpeg+X624 来编码视频数据 YUV/RGB 输出 H264 数据，
FFmpeg+fdk_aac 来编码音频数据 PCM 输出 AAC 数据。

### 四、根据所选流媒体协议封包音视频数据

将音频，视频打包成 packet。

### 五、与服务器交互发送封包数据

根据所选流媒体协议，发送相应指令连接服务器，连接服务器成功后，就可以发送 packet 数据了。


## Part 2. 拉流端

拉流，就是从流媒体服务器获取音频，视频数据。

### 一、解析协议

播放器端根据URL解析所用的流媒体协议（RTMP，HLS）。

### 二、解封装

解封装，就是 demux 的过程，从容器格式（FLV，TS）中，分离出音视频数据。

### 三、解码

解码，就是把获取到的数据解压缩，恢复成原始数据。解码就是将 H264 变成 YUV，AAC 变成 PCM。

解码可以使用软解码，硬解码。

软解码就是利用 CPU 资源去解压缩数据，采用的方式是FFmpeg解码。

硬解码，对于 iOS 平台来说，可以使用 VideoToolbox.Framework（该框架只能在iOS 8.0及以上系统使用）
硬解码视频数据。Android 平台上，可以使用 MediaCodec 来硬解码视频数据。

### 四、渲染数据

采用 OpenGL 渲染 YUV 数据，呈现视频画面。将PCM送入设备的硬件资源播放，产生声音。

iOS 播放流式音频，使用 Audio Queue 的方式，即，利用 AudioToolbox.Framework 框架。